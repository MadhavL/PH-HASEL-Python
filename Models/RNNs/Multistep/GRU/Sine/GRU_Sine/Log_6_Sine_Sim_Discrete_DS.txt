#2nd best GRU, 64 hidden size, 1 layer, no tanh.
Look back: 200
Epochs: 320
Train ratio: 0.8
Batch size: 40000
Learning rate: 0.01
Weight Decay: 0
Momentum: 0.9
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─GRU: 1-1                               [-1, 200, 64]             13,056
├─Sequential: 1-2                        [-1, 1400, 1]             --
|    └─Linear: 2-1                       [-1, 1400, 1]             65
|    └─Sigmoid: 2-2                      [-1, 1400, 1]             --
==========================================================================================
Total params: 13,121
Trainable params: 13,121
Non-trainable params: 0
Total mult-adds (M): 0.01
==========================================================================================
Input size (MB): 2.14
Forward/backward pass size (MB): 0.11
Params size (MB): 0.05
Estimated Total Size (MB): 2.29
==========================================================================================